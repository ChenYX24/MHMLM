# Layer2 Stage 2 训练配置 (v2 - improved)
# Stage 1: InfoNCE + Amount (500 epochs, hidden=768, 8 layers)
# Stage 2: + Yield prediction + projection head + optimized embedding
#
# Changes from v1:
# - 500 epochs (was 100)
# - yield_mode: both (was soft_bin_only) — CE+MSE for better bin_acc
# - yield_class_weights: true — inverse-frequency weighting
# - yield_weight: 3.0 (was 2.0)
# - amt_lambda: 0.3 (was 0.5) — focus on emb+yield
# - grad_accumulation_steps: 2 (was 4)
# - warmup_steps: 1000 (was 500)
# - eval_steps: 500 (was 1000)
# - save_steps: 1000 (was 2000)
# - Yield-focused masking (45% yield tasks)
# - AMP enabled

# 模型配置 (must match Stage 1 checkpoint)
mol_emb_dim: 256
hidden_dim: 768
n_layers: 8
n_heads: 12
dropout: 0.2
num_roles: 11
num_token_types: 2
tau: 0.07
learnable_tau: true
symmetric_ince: true
use_projection_head: true

# 数据配置 (decompressed)
data_path: "/data1/chenyuxuan/Layer2/data/ord_layer2_v2/layer2_train.jsonl"
val_data_path: "/data1/chenyuxuan/Layer2/data/ord_layer2_v2/layer2_val.jsonl"
use_indexed_dataset: true

# 训练配置
batch_size: 64
learning_rate: 0.0003
weight_decay: 0.05
num_epochs: 500
warmup_steps: 1000
min_lr: 0.000001
grad_accumulation_steps: 2
save_steps: 1000
eval_steps: 500
log_steps: 50
num_workers: 4

# AMP (Mixed Precision)
use_amp: true

# Loss 权重
emb_lambda: 1.0
amt_lambda: 0.3
yield_weight: 3.0
yield_mode: "both"
yield_soft_bin_temperature: 0.1
yield_reg_lambda: 1.0
yield_class_weights: true

# Masking (Stage 2: yield-focused, 45% yield tasks)
p_forward: 0.20
p_retro: 0.15
p_condition: 0.10
p_random: 0.05
p_yield_full: 0.25
p_yield_with_product: 0.25

# Resume from Stage 1
resume_from: "/data1/chenyuxuan/Layer2/ckpt/0115/layer2_pretrain.pt"

# 其他
tf32: true
global_seed: 42
results_dir: "/data1/chenyuxuan/checkpoint/layer2_stage2"
