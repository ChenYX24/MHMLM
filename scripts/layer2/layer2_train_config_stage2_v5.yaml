# Layer2 Stage 2 训练配置 (v5 - Two-Phase Training)
#
# Phase A (step 0 → 1500): Frozen backbone, high head_lr, no EMA
#   - Let yield + embedding heads converge first
#   - head_lr=2e-3, no label smoothing, head_dropout=0.15
#
# Phase B (step 1500+): Unfreeze top 2 layers + EMA + regularization
#   - backbone_lr=5e-5, phase_b_head_lr=5e-4 (lower than Phase A)
#   - EMA=0.999, label_smoothing=0.1
#   - patience=60 (generous early stopping)
#
# Best model selection: composite = yield_bin_acc + 0.3 * emb_top1
# Also saves best_by_yield checkpoint separately
#
# v4 lessons: best@step600 was too early (yield=0.274),
#   step6000 had yield=0.358 but wasn't selected.

# 模型配置 (must match Stage 1 checkpoint)
mol_emb_dim: 256
hidden_dim: 768
n_layers: 8
n_heads: 12
dropout: 0.2
num_roles: 11
num_token_types: 2
tau: 0.07
learnable_tau: true
symmetric_ince: true
use_projection_head: true

# Head dropout (moderate in Phase A; same for Phase B)
head_dropout: 0.15

# 数据配置
data_path: "/data1/chenyuxuan/Layer2/data/ord_layer2_v2/layer2_train.jsonl"
val_data_path: "/data1/chenyuxuan/Layer2/data/ord_layer2_v2/layer2_val.jsonl"
use_indexed_dataset: true

# 训练配置
batch_size: 64
weight_decay: 0.05
num_epochs: 300
warmup_steps: 300
min_lr: 0.000001
grad_accumulation_steps: 2
save_steps: 600
eval_steps: 200
log_steps: 50
num_workers: 4

# ===== Two-Phase Strategy =====
freeze_backbone: true

# Phase A: frozen backbone, heads-only warmup
head_lr: 0.002                    # 2e-3, aggressive head training
yield_label_smoothing: 0.0        # no smoothing in Phase A (clear signal)

# Phase transition
phase_b_step: 1500                # switch at step 1500 (~55 epochs)

# Phase B: partial unfreeze
unfreeze_top_layers: 2            # layers 6,7
backbone_lr: 0.00005              # 5e-5 (stronger than v4's 3e-5)
phase_b_head_lr: 0.0005           # 5e-4 (slower than Phase A)
phase_b_warmup: 200               # warmup for Phase B optimizer
phase_b_label_smoothing: 0.1      # enable in Phase B

# EMA: deferred to Phase B
ema_decay: 0.999

# Best model selection
best_selection: "composite"        # composite = yield_bin_acc + alpha * emb_top1
composite_alpha: 0.3

# Early stopping (generous: 60 evals * 200 steps = 12000 steps patience)
patience: 60

# AMP
use_amp: true

# Loss 权重
emb_lambda: 1.0
amt_lambda: 0.3
yield_weight: 3.0
yield_mode: "both"
yield_soft_bin_temperature: 0.1
yield_reg_lambda: 1.0
yield_class_weights: true

# Masking (yield-focused, 50%)
p_forward: 0.20
p_retro: 0.15
p_condition: 0.10
p_random: 0.05
p_yield_full: 0.25
p_yield_with_product: 0.25

# Resume from Stage 1
resume_from: "/data1/chenyuxuan/Layer2/ckpt/0115/layer2_pretrain.pt"

# 其他
tf32: true
global_seed: 42
results_dir: "/data1/chenyuxuan/checkpoint/layer2_stage2"
