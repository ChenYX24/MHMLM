#!/usr/bin/env python3
"""
æ‰¹é‡æ›¿æ¢æ–‡ä»¶ä¸­çš„è·¯å¾„
è¾“å‡ºæ‰€æœ‰è·¯å¾„åˆ°æ–‡ä»¶ä¾›ç¡®è®¤
"""
import os
import re
import json
from pathlib import Path
from typing import List, Tuple, Dict, Any
from collections import defaultdict

# è·¯å¾„æ˜ å°„è§„åˆ™ (original_path, target_path)
PATH_MAPPINGS = [
    # æ³¨æ„ï¼šé¡ºåºå¾ˆé‡è¦ï¼Œå…ˆæ›¿æ¢é•¿çš„è·¯å¾„ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
    ("/data2/zengzheni/chenyuxuan/Project/MHMLM", "/data1/chenyuxuan/MHMLM"),
    ("/data2/zengzheni/chenyuxuan/Project/MSMLM", "/data1/chenyuxuan/MSMLM"),
    ("/data2/zengzheni/xiaoyunduo/Layer2", "/data1/chenyuxuan/Layer2"),
    ("/data2/zengzheni/cpt_data", "/data1/chenyuxuan/train_data/cpt_data"),
    ("/data2/zengzheni/SFT_DATA", "/data1/chenyuxuan/train_data/SFT_DATA"),
    ("/data1/zengzheni/base_model", "/data1/chenyuxuan/base_model"),
    ("/data1/zengzheni/checkpoint", "/data1/chenyuxuan/checkpoint"),
    # æ–°å¢ï¼šä» valid_unreplaced_paths.json ä¸­ç¡®è®¤çš„æ˜ å°„ï¼ˆsuggested_path å­˜åœ¨ï¼‰
    ("/data2/zengzheni/checkpoint", "/data1/chenyuxuan/checkpoint"),
    ("/data2/zengzheni/model", "/data1/chenyuxuan/base_model"),
    ("/data1/zengzheni/model", "/data1/chenyuxuan/base_model"),
    ("/data2/zengzheni/lvchangwei", "/data1/lvchangwei"),
    # Conda è·¯å¾„æ˜ å°„
    ("/data2/zengzheni/chenyuxuan/miniconda3", "/home/chenyuxuan/miniconda3"),
]

# éœ€è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•å
INCLUDE_EXTENSIONS = {'.py', '.yaml', '.yml', '.sh', '.json', '.md', '.txt', '.jsonl'}

# æ’é™¤çš„ç›®å½•
EXCLUDE_DIRS = {'.git', '__pycache__', '.venv', 'node_modules', '.pytest_cache', 'artifacts', 'scripts/utils'}

# æ’é™¤çš„æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ç”Ÿæˆçš„æˆ–ä¸éœ€è¦ä¿®æ”¹çš„ï¼‰
EXCLUDE_FILES = {
    'batch_replace_paths.py',  # è‡ªå·±
}

# åˆ›å»ºè·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„å­—å…¸
PATH_MAP_DICT = {old: new for old, new in PATH_MAPPINGS}


def should_process_file(file_path: Path) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶"""
    # æ£€æŸ¥æ‰©å±•å
    if file_path.suffix not in INCLUDE_EXTENSIONS:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
    if file_path.name in EXCLUDE_FILES:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
    for part in file_path.parts:
        if part in EXCLUDE_DIRS:
            return False
    
    # æ’é™¤ scripts/utils ç›®å½•åŠå…¶å­ç›®å½•
    try:
        parts = file_path.parts
        if 'scripts' in parts and 'utils' in parts:
            scripts_idx = parts.index('scripts')
            if scripts_idx + 1 < len(parts) and parts[scripts_idx + 1] == 'utils':
                return False
    except (ValueError, IndexError):
        pass
    
    return True


def extract_variable_name(line: str, path: str) -> str:
    """å°è¯•ä»è¡Œä¸­æå–å˜é‡å"""
    # å°è¯•åŒ¹é…å¸¸è§çš„å˜é‡èµ‹å€¼æ¨¡å¼
    patterns = [
        r'(\w+)\s*[:=]\s*["\']?' + re.escape(path),  # var = "path" æˆ– var: "path"
        r'["\']?' + re.escape(path) + r'["\']?\s*[:=]\s*(\w+)',  # "path" = var
        r'(\w+)\s*=\s*["\']?' + re.escape(path),  # var = "path"
        r'--(\w+)\s+["\']?' + re.escape(path),  # --arg "path"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, line, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return ""


def find_paths_in_line(line: str, line_num: int, file_path: Path) -> List[Dict[str, Any]]:
    """åœ¨è¡Œä¸­æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æ˜ å°„çš„è·¯å¾„"""
    found_paths = []
    
    for old_path, new_path in PATH_MAPPINGS:
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        escaped_old = re.escape(old_path)
        # åŒ¹é…è·¯å¾„ï¼ˆå¯èƒ½åé¢è·Ÿç€ / æˆ–å…¶ä»–å­—ç¬¦ï¼Œæˆ–åœ¨å¼•å·ä¸­ï¼‰
        pattern = escaped_old + r'(?=/|"|\'| |\n|$|,|\)|]|})'
        
        matches = list(re.finditer(pattern, line))
        for match in matches:
            start_pos = match.start()
            end_pos = match.end()
            
            # è·å–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„30ä¸ªå­—ç¬¦ï¼‰
            context_start = max(0, start_pos - 30)
            context_end = min(len(line), end_pos + 30)
            context = line[context_start:context_end]
            
            # å°è¯•æå–å˜é‡å
            var_name = extract_variable_name(line, old_path)
            
            found_paths.append({
                "file_path": str(file_path),
                "line_number": line_num,
                "variable_name": var_name,
                "context": context.strip(),
                "original_path": old_path,
                "replaced_path": new_path,
                "position": (start_pos, end_pos)
            })
    
    return found_paths


def scan_file_for_paths(file_path: Path, root_dir: Path) -> Tuple[List[Dict], List[Dict]]:
    """æ‰«ææ–‡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰éœ€è¦æ›¿æ¢å’Œä¸éœ€è¦æ›¿æ¢çš„è·¯å¾„"""
    replaced_paths = []  # å·²æ‰¾åˆ°å¹¶å¯ä»¥æ›¿æ¢çš„è·¯å¾„
    all_old_paths = set()  # æ‰€æœ‰æ—§è·¯å¾„çš„é›†åˆ
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                lines = f.readlines()
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return [], []
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return [], []
    
    # æ‰«ææ¯ä¸€è¡Œ
    for line_num, line in enumerate(lines, 1):
        # æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æ˜ å°„çš„è·¯å¾„
        found = find_paths_in_line(line, line_num, file_path.relative_to(root_dir))
        replaced_paths.extend(found)
        
        # è®°å½•æ‰€æœ‰æ—§è·¯å¾„ï¼ˆç”¨äºåç»­æ£€æŸ¥æœªæ›¿æ¢çš„ï¼‰
        for old_path in PATH_MAP_DICT.keys():
            if old_path in line:
                all_old_paths.add(old_path)
    
    return replaced_paths, []


def find_unreplaced_paths(file_path: Path, root_dir: Path) -> List[Dict[str, Any]]:
    """æŸ¥æ‰¾æ–‡ä»¶ä¸­æœªæ˜ å°„çš„æ—§è·¯å¾„ï¼ˆåŒ…å« /data2/zengzheni æˆ– /data1/zengzheni ä½†ä¸åœ¨æ˜ å°„è§„åˆ™ä¸­ï¼‰"""
    unreplaced = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                lines = f.readlines()
        except:
            return []
    except:
        return []
    
    # å®šä¹‰éœ€è¦æ£€æµ‹çš„æ—§è·¯å¾„å‰ç¼€
    old_prefixes = ['/data2/zengzheni', '/data1/zengzheni']
    
    # è·å–æ‰€æœ‰å·²æ˜ å°„çš„è·¯å¾„å‰ç¼€ï¼ˆç”¨äºæ’é™¤ï¼‰
    mapped_prefixes = set()
    for old_path, _ in PATH_MAPPINGS:
        # æå–å‰ç¼€ï¼ˆåˆ°ç¬¬ä¸€ä¸ªå­ç›®å½•ï¼‰
        parts = old_path.split('/')
        if len(parts) >= 4:
            mapped_prefixes.add('/'.join(parts[:4]))  # ä¾‹å¦‚ /data2/zengzheni/chenyuxuan
    
    # åŒ¹é…å®Œæ•´è·¯å¾„çš„æ­£åˆ™è¡¨è¾¾å¼
    # åŒ¹é… /data2/zengzheni/... æˆ– /data1/zengzheni/... æ ¼å¼çš„è·¯å¾„
    path_pattern = re.compile(r'(/data[12]/zengzheni/[^"\' \n,\)\]}]+)')
    
    for line_num, line in enumerate(lines, 1):
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„è·¯å¾„
        matches = path_pattern.finditer(line)
        for match in matches:
            found_path = match.group(1)
            
            # æ£€æŸ¥è¿™ä¸ªè·¯å¾„æ˜¯å¦å·²ç»åœ¨æ˜ å°„è§„åˆ™ä¸­
            is_mapped = False
            for old_path, new_path in PATH_MAPPINGS:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·²æ˜ å°„è·¯å¾„çš„å‰ç¼€æˆ–å®Œå…¨åŒ¹é…
                if found_path.startswith(old_path + '/') or found_path == old_path:
                    is_mapped = True
                    break
            
            # å¦‚æœä¸åœ¨æ˜ å°„è§„åˆ™ä¸­ï¼Œæ·»åŠ åˆ°æœªæ›¿æ¢åˆ—è¡¨
            if not is_mapped:
                # è·å–ä¸Šä¸‹æ–‡
                start_pos = match.start()
                end_pos = match.end()
                context_start = max(0, start_pos - 30)
                context_end = min(len(line), end_pos + 30)
                context = line[context_start:context_end].strip()
                
                # å°è¯•æå–å˜é‡å
                var_name = extract_variable_name(line, found_path)
                
                # å°è¯•æ¨æ–­å»ºè®®çš„æ–°è·¯å¾„
                suggested_path = ""
                if found_path.startswith('/data2/zengzheni/checkpoint'):
                    suggested_path = found_path.replace('/data2/zengzheni/checkpoint', '/data1/chenyuxuan/checkpoint')
                elif found_path.startswith('/data2/zengzheni/lvchangwei'):
                    # è¿™ä¸ªè·¯å¾„éœ€è¦ç”¨æˆ·ç¡®è®¤ï¼Œæš‚æ—¶ä¿æŒåŸæ ·æˆ–æä¾›å»ºè®®
                    suggested_path = found_path.replace('/data2/zengzheni/lvchangwei', '/data1/lvchangwei')
                elif found_path.startswith('/data1/zengzheni/checkpoint'):
                    suggested_path = found_path.replace('/data1/zengzheni/checkpoint', '/data1/chenyuxuan/checkpoint')
                elif found_path.startswith('/data1/zengzheni/base_model'):
                    suggested_path = found_path.replace('/data1/zengzheni/base_model', '/data1/chenyuxuan/base_model')
                else:
                    # å…¶ä»–æƒ…å†µï¼Œå°è¯•é€šç”¨æ›¿æ¢
                    if '/data2/zengzheni' in found_path:
                        suggested_path = found_path.replace('/data2/zengzheni', '/data1/chenyuxuan')
                    elif '/data1/zengzheni' in found_path:
                        suggested_path = found_path.replace('/data1/zengzheni', '/data1/chenyuxuan')
                
                unreplaced.append({
                    "file_path": str(file_path.relative_to(root_dir)),
                    "line_number": line_num,
                    "variable_name": var_name,
                    "context": context,
                    "original_path": found_path,
                    "suggested_path": suggested_path,
                    "note": "è·¯å¾„ä¸åœ¨æ˜ å°„è§„åˆ™ä¸­ï¼Œéœ€è¦æ‰‹åŠ¨ç¡®è®¤"
                })
    
    return unreplaced


def process_directory(root_dir: Path, mappings: List[Tuple[str, str]], dry_run: bool = False):
    """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    root_dir = Path(root_dir)
    
    print(f"ğŸ” æ‰«æç›®å½•: {root_dir}")
    print(f"ğŸ“‹ è·¯å¾„æ˜ å°„è§„åˆ™:")
    for old, new in mappings:
        print(f"   {old}")
        print(f"   â†’ {new}")
    print()
    
    all_replaced = []
    all_unreplaced = []
    total_files = 0
    
    # éå†æ‰€æœ‰æ–‡ä»¶
    for file_path in root_dir.rglob('*'):
        if not file_path.is_file():
            continue
        
        if not should_process_file(file_path):
            continue
        
        total_files += 1
        
        # æ‰«ææ–‡ä»¶
        replaced, _ = scan_file_for_paths(file_path, root_dir)
        unreplaced = find_unreplaced_paths(file_path, root_dir)
        
        all_replaced.extend(replaced)
        all_unreplaced.extend(unreplaced)
        
        if replaced:
            print(f"âœ… {file_path.relative_to(root_dir)}: æ‰¾åˆ° {len(replaced)} ä¸ªå¯æ›¿æ¢è·¯å¾„")
    
    print()
    print("=" * 60)
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   æ‰«ææ–‡ä»¶æ•°: {total_files}")
    print(f"   æ‰¾åˆ°å¯æ›¿æ¢è·¯å¾„: {len(all_replaced)} ä¸ª")
    print(f"   éœ€è¦ç¡®è®¤çš„è·¯å¾„: {len(all_unreplaced)} ä¸ª")
    print("=" * 60)
    
    # ä¿å­˜ç»“æœ
    output_dir = root_dir / "scripts" / "utils" / "path_replacement_logs"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    replaced_file = output_dir / "replaced_paths.json"
    unreplaced_file = output_dir / "unreplaced_paths.json"
    
    # ä¿å­˜å·²æ›¿æ¢è·¯å¾„
    with open(replaced_file, 'w', encoding='utf-8') as f:
        json.dump(all_replaced, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ å·²ä¿å­˜å¯æ›¿æ¢è·¯å¾„åˆ°: {replaced_file}")
    print(f"   å…± {len(all_replaced)} æ¡è®°å½•")
    
    # ä¿å­˜æœªæ›¿æ¢è·¯å¾„
    with open(unreplaced_file, 'w', encoding='utf-8') as f:
        json.dump(all_unreplaced, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ å·²ä¿å­˜å¾…ç¡®è®¤è·¯å¾„åˆ°: {unreplaced_file}")
    print(f"   å…± {len(all_unreplaced)} æ¡è®°å½•")
    
    # å¦‚æœä¸åœ¨dry_runæ¨¡å¼ï¼Œæ‰§è¡Œå®é™…æ›¿æ¢
    if not dry_run and all_replaced:
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œæ›¿æ¢...")
        replace_paths_in_files(root_dir, all_replaced)
    
    return all_replaced, all_unreplaced


def replace_paths_in_files(root_dir: Path, replacements: List[Dict[str, Any]]):
    """æ ¹æ®è®°å½•æ‰§è¡Œå®é™…æ›¿æ¢"""
    # æŒ‰æ–‡ä»¶åˆ†ç»„
    files_to_modify = defaultdict(list)
    for rep in replacements:
        file_path = root_dir / rep["file_path"]
        files_to_modify[file_path].append(rep)
    
    total_replacements = 0
    
    for file_path, reps in files_to_modify.items():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    content = f.read()
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
                continue
        
        original_content = content
        
        # æŒ‰é¡ºåºåº”ç”¨æ‰€æœ‰æ›¿æ¢ï¼ˆä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»ï¼‰
        for rep in sorted(reps, key=lambda x: x["position"][0], reverse=True):
            old_path = rep["original_path"]
            new_path = rep["replaced_path"]
            
            # è½¬ä¹‰å¹¶æ›¿æ¢
            escaped_old = re.escape(old_path)
            pattern = escaped_old + r'(?=/|"|\'| |\n|$|,|\)|]|})'
            content = re.sub(pattern, new_path, content, count=1)
        
        # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶
        if content != original_content:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                total_replacements += len(reps)
                print(f"âœ… {file_path.relative_to(root_dir)}: æ›¿æ¢äº† {len(reps)} å¤„")
            except Exception as e:
                print(f"âš ï¸ å†™å…¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    print(f"\nâœ… æ€»å…±æ›¿æ¢äº† {total_replacements} å¤„è·¯å¾„")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡æ›¿æ¢æ–‡ä»¶ä¸­çš„è·¯å¾„')
    parser.add_argument('--root', type=str, default='/data1/chenyuxuan/MHMLM',
                       help='è¦å¤„ç†çš„æ ¹ç›®å½•')
    parser.add_argument('--dry-run', action='store_true', default=True,
                       help='åªæ£€æŸ¥ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰')
    parser.add_argument('--execute', action='store_true',
                       help='æ‰§è¡Œå®é™…æ›¿æ¢ï¼ˆè¦†ç›–--dry-runï¼‰')
    parser.add_argument('--mapping', type=str, nargs=2, action='append',
                       help='è‡ªå®šä¹‰æ˜ å°„è§„åˆ™: --mapping old_path new_path')
    
    args = parser.parse_args()
    
    root_dir = Path(args.root)
    if not root_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {root_dir}")
        return
    
    # ä½¿ç”¨è‡ªå®šä¹‰æ˜ å°„æˆ–é»˜è®¤æ˜ å°„
    mappings = PATH_MAPPINGS
    if args.mapping:
        mappings = [(old, new) for old, new in args.mapping]
    
    dry_run = not args.execute
    
    if dry_run:
        print("ğŸ” æ‰«ææ¨¡å¼ï¼ˆä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶ï¼‰")
        print("   ä½¿ç”¨ --execute æ¥å®é™…æ‰§è¡Œæ›¿æ¢")
        print()
    else:
        print("âš ï¸  æ‰§è¡Œæ¨¡å¼ï¼ˆå°†å®é™…ä¿®æ”¹æ–‡ä»¶ï¼‰")
        print()
    
    replaced, unreplaced = process_directory(root_dir, mappings, dry_run=dry_run)
    
    if dry_run and replaced:
        print("\nğŸ’¡ ä½¿ç”¨ --execute æ¥å®é™…æ‰§è¡Œæ›¿æ¢")


if __name__ == '__main__':
    main()
