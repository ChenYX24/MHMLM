#!/usr/bin/env python3
"""
ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆ LLM è®­ç»ƒæ•°æ®
Pipeline: query -> LLM -> Layer2 -> ç”Ÿæˆè®­ç»ƒæ•°æ®

ç”Ÿæˆçš„æ•°æ®æ ¼å¼ï¼š
{
    "input": "åŸå§‹ query",
    "intermediate": "ç¬¬ä¸€è½® LLM è¾“å‡ºï¼ˆåŒ…å«ååº”ç‰© SMILESï¼‰",
    "layer2_info": {
        "yield_bin": 5,
        "yield_reg": 0.75,
        "embedding": [...]
    },
    "output": "æœ€ç»ˆ LLM è¾“å‡ºï¼ˆä½¿ç”¨ layer2 ä¿¡æ¯åï¼‰"
}
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
from tqdm import tqdm
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from sft_tester import MolAwareGenerator2


def load_queries(input_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½æŸ¥è¯¢æ•°æ®"""
    queries = []
    with open(input_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                data = json.loads(line)
                queries.append(data)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯ JSONï¼Œå½“ä½œçº¯æ–‡æœ¬
                queries.append({"input": line})
    return queries


def load_chembench_data(task: str = "product", split: str = "train") -> List[Dict[str, Any]]:
    """ä» ChemBench åŠ è½½æ•°æ®"""
    try:
        from datasets import load_dataset
    except ImportError:
        raise RuntimeError("Please install datasets: pip install datasets")
    
    REPO_ID = "AI4Chem/ChemBench4K"
    BENCH_FILES = {
        "product": {
            "dev": "dev/Product_Prediction_benchmark.json",
            "test": "test/Product_Prediction_benchmark.json",
        },
        "retro": {
            "dev": "dev/Retrosynthesis_benchmark.json",
            "test": "test/Retrosynthesis_benchmark.json",
        },
        "yield": {
            "dev": "dev/Yield_Prediction_benchmark.json",
            "test": "test/Yield_Prediction_benchmark.json",
        },
    }
    
    if task not in BENCH_FILES:
        raise ValueError(f"Unsupported task: {task}")
    
    # ChemBench æ²¡æœ‰ train splitï¼Œä½¿ç”¨ dev ä½œä¸ºè®­ç»ƒæ•°æ®
    if split == "train":
        print("[INFO] ChemBench æ²¡æœ‰ train splitï¼Œä½¿ç”¨ dev ä½œä¸ºè®­ç»ƒæ•°æ®")
        split = "dev"
    
    if split not in BENCH_FILES[task]:
        raise ValueError(f"Unsupported split: {split}")
    
    relpath = BENCH_FILES[task][split]
    url = f"https://huggingface.co/datasets/{REPO_ID}/resolve/main/{relpath}"
    
    print(f"[INFO] Loading ChemBench data: {task}/{split}")
    print(f"[INFO] URL: {url}")
    
    ds = load_dataset("json", data_files={split: url}, split=split)
    
    # è½¬æ¢ä¸ºæŸ¥è¯¢æ ¼å¼
    queries = []
    for sample in ds:
        question = sample.get("question", "")
        queries.append({"input": question})
    
    print(f"[INFO] Loaded {len(queries)} samples from ChemBench")
    return queries


def save_results(results: List[Dict[str, Any]], output_path: str):
    """ä¿å­˜ç»“æœåˆ° JSONL"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in results:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')


def generate_training_data(
    generator: MolAwareGenerator2,
    queries: List[Dict[str, Any]],
    output_path: str,
    task_type: Optional[str] = None,
):
    """
    ç”Ÿæˆè®­ç»ƒæ•°æ®
    
    Args:
        generator: MolAwareGenerator2 å®ä¾‹
        queries: æŸ¥è¯¢åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        task_type: ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ "reaction_prediction"ï¼‰
    """
    results = []
    
    for i, query_data in enumerate(tqdm(queries, desc="ç”Ÿæˆè®­ç»ƒæ•°æ®")):
        query = query_data.get("input", query_data.get("query", ""))
        if not query:
            continue
        
        try:
            # ä½¿ç”¨ generate_with_layer2 ç”Ÿæˆå®Œæ•´ pipeline çš„ç»“æœï¼Œå¹¶è·å–ä¸­é—´ç»“æœ
            result = generator.generate_with_layer2(
                prompt=query,
                add_dialog_wrapper=True,
                max_new_tokens=512,
                do_sample=True,
                temperature=0.7,
                task_type=task_type,
                return_intermediate=True,  # è¿”å›ä¸­é—´ç»“æœ
            )
            
            # result ç°åœ¨æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« first_response, layer2_info, final_response
            if isinstance(result, dict):
                first_response = result.get("first_response", "")
                layer2_info = result.get("layer2_info", {})
                final_response = result.get("final_response", "")
                
                # è§£æç¬¬ä¸€è½®è¾“å‡ºä¸­çš„ JSONï¼ˆåŒ…å«åˆ†å­ä¿¡æ¯å’Œè§’è‰²ï¼‰
                molecules_info = None
                try:
                    import json
                    import re
                    # å°è¯•ä» first_response ä¸­æå– JSON
                    json_match = re.search(r'\{.*\}', first_response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                        parsed = json.loads(json_str)
                        if "molecules" in parsed:
                            molecules_info = parsed["molecules"]
                except:
                    pass
                
                # æ„å»ºè®­ç»ƒæ•°æ®
                training_item = {
                    "input": query,
                    "intermediate": first_response,  # ç¬¬ä¸€è½® JSON è¾“å‡º
                    "molecules_info": molecules_info,  # è§£æåçš„åˆ†å­ä¿¡æ¯ï¼ˆåŒ…å«è§’è‰²ï¼‰
                    "layer2_info": {
                        "yield_bin": layer2_info.get("yield_bin") if layer2_info else None,
                        "yield_reg": layer2_info.get("yield_reg") if layer2_info else None,
                        # embedding æ˜¯ tensorï¼Œåªä¿å­˜å½¢çŠ¶ä¿¡æ¯ï¼ˆå®é™… embedding åœ¨è®­ç»ƒæ—¶åŠ¨æ€ç”Ÿæˆï¼‰
                        "embedding_shape": list(layer2_info.get("embedding", torch.tensor([])).shape) if layer2_info and layer2_info.get("embedding") is not None else None,
                    },
                    "output": final_response,  # æœ€ç»ˆ LLM è¾“å‡º
                }
            else:
                # å…¼å®¹æ—§æ¥å£ï¼šå¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²
                training_item = {
                    "input": query,
                    "intermediate": "",
                    "layer2_info": {},
                    "output": result,
                }
            
            results.append(training_item)
            
        except Exception as e:
            print(f"âŒ å¤„ç†æŸ¥è¯¢ {i} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ä¿å­˜ç»“æœ
    save_results(results, output_path)
    print(f"âœ… å·²ä¿å­˜ {len(results)} æ¡è®­ç»ƒæ•°æ®åˆ° {output_path}")


def main():
    # é»˜è®¤è·¯å¾„
    DEFAULT_INPUT = None  # é»˜è®¤ä½¿ç”¨ ChemBench
    DEFAULT_OUTPUT = "/data1/chenyuxuan/MHMLM/scripts/layer2_llm/data/training_data.jsonl"
    DEFAULT_CONFIG = "/data1/chenyuxuan/MHMLM/configs/qwen3_sft_epoch2_2.yaml"
    
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ Layer2-LLM è”åˆè®­ç»ƒæ•°æ®")
    parser.add_argument("--input", type=str, default=DEFAULT_INPUT, 
                       help="è¾“å…¥æŸ¥è¯¢æ–‡ä»¶ï¼ˆJSONLï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ ChemBench æ•°æ®")
    parser.add_argument("--output", type=str, default=DEFAULT_OUTPUT, 
                       help=f"è¾“å‡ºè®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆJSONLï¼‰ï¼Œé»˜è®¤: {DEFAULT_OUTPUT}")
    parser.add_argument("--config", type=str, default=DEFAULT_CONFIG, 
                       help=f"æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤: {DEFAULT_CONFIG}")
    parser.add_argument("--task_type", type=str, default="reaction_prediction", help="ä»»åŠ¡ç±»å‹ï¼Œé»˜è®¤: reaction_prediction")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡ï¼Œé»˜è®¤: cuda:0")
    
    # ChemBench ç›¸å…³å‚æ•°
    parser.add_argument("--use_chembench", action="store_true", help="ä½¿ç”¨ ChemBench æ•°æ®ï¼ˆå¦‚æœä¸æŒ‡å®š --input åˆ™é»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--chembench_task", type=str, default="product", choices=["product", "retro", "yield"], 
                       help="ChemBench ä»»åŠ¡ç±»å‹ï¼Œé»˜è®¤: product")
    parser.add_argument("--chembench_split", type=str, default="train", choices=["train", "dev", "test"],
                       help="ChemBench æ•°æ®åˆ’åˆ†ï¼Œé»˜è®¤: train")
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    if args.config.endswith('.yaml') or args.config.endswith('.yml'):
        import yaml
        with open(args.config, 'r', encoding='utf-8') as f:
            train_cfg = yaml.safe_load(f)
    else:
        # å‡è®¾æ˜¯ JSON
        with open(args.config, 'r', encoding='utf-8') as f:
            train_cfg = json.load(f)
    
    # å°†è®­ç»ƒé…ç½®è½¬æ¢ä¸ºç”Ÿæˆå™¨é…ç½®æ ¼å¼
    # æ£€æŸ¥è®¾å¤‡æ˜¯å¦å¯ç”¨
    device = args.device
    if device.startswith("cuda:"):
        import torch
        if not torch.cuda.is_available():
            print(f"âš ï¸  è­¦å‘Š: CUDA ä¸å¯ç”¨ï¼Œä½†è®¾å¤‡è®¾ç½®ä¸º {device}")
            print("   å°è¯•ä½¿ç”¨ CPU æˆ–æ£€æŸ¥ CUDA_VISIBLE_DEVICES ç¯å¢ƒå˜é‡")
            # å¦‚æœ CUDA ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU
            device = "cpu"
        else:
            # æ£€æŸ¥æŒ‡å®šçš„ GPU æ˜¯å¦åœ¨å¯è§èŒƒå›´å†…
            gpu_id = int(device.split(":")[-1])
            visible_gpus = os.environ.get("CUDA_VISIBLE_DEVICES", "")
            if visible_gpus:
                visible_list = [int(x) for x in visible_gpus.split(",") if x.strip().isdigit()]
                if visible_list:
                    # CUDA_VISIBLE_DEVICES é‡æ–°æ˜ å°„äº† GPU ID
                    # å¦‚æœè®¾ç½®äº† CUDA_VISIBLE_DEVICES=0,1,2,3ï¼Œé‚£ä¹ˆ cuda:0 å®é™…æŒ‡å‘ç¬¬ä¸€ä¸ªå¯è§ GPU
                    # æ‰€ä»¥å¦‚æœæŒ‡å®šäº† cuda:0ï¼Œåº”è¯¥ä½¿ç”¨ cuda:0ï¼ˆå› ä¸ºå·²ç»é‡æ–°æ˜ å°„ï¼‰
                    # ä½†å¦‚æœæŒ‡å®šçš„ ID è¶…å‡ºäº†å¯è§åˆ—è¡¨èŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è§çš„ GPU
                    if gpu_id >= len(visible_list):
                        device = "cuda:0"  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è§ GPUï¼ˆé‡æ–°æ˜ å°„åæ˜¯ cuda:0ï¼‰
                        print(f"âš ï¸  è­¦å‘Š: GPU {gpu_id} è¶…å‡ºå¯è§èŒƒå›´ï¼Œä½¿ç”¨ cuda:0ï¼ˆæ˜ å°„åˆ°ç‰©ç† GPU {visible_list[0]}ï¼‰")
            else:
                # å¦‚æœæ²¡æœ‰è®¾ç½® CUDA_VISIBLE_DEVICESï¼Œç›´æ¥ä½¿ç”¨æŒ‡å®šçš„è®¾å¤‡
                pass
    
    cfg = {
        "ckpt_dir": train_cfg.get("paths", {}).get("checkpoint_dir") or train_cfg.get("paths", {}).get("llm_name_or_path"),
        "device": device,
        "dtype": "bf16",  # é»˜è®¤ä½¿ç”¨ bf16
        "debug": False,
    }
    
    # æ·»åŠ  token_classifier_pathï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    token_classifier_path = train_cfg.get("paths", {}).get("mlp_token_classifier_path")
    if token_classifier_path:
        cfg["token_classifier_path"] = token_classifier_path
    
    # é»˜è®¤å¯ç”¨ Layer2ï¼ˆè¿™æ˜¯ Layer2 è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬ï¼‰
    import yaml
    script_dir = Path(__file__).parent.resolve()
    project_root = script_dir.parent.parent
    layer2_config_path = project_root / "modules" / "layer2_component" / "layer2_config.yaml"
    if layer2_config_path.exists():
        with open(layer2_config_path, 'r', encoding='utf-8') as f:
            layer2_config = yaml.safe_load(f)
        # ä¼ é€’é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œè®© Layer2Inferer è‡ªå·±åŠ è½½
        cfg["layer2"] = {
            "config_path": str(layer2_config_path),
            **layer2_config,  # ä¹ŸåŒ…å«é…ç½®å†…å®¹ï¼Œä¾›å…¶ä»–éƒ¨åˆ†ä½¿ç”¨
        }
    else:
        print(f"[WARNING] Layer2 config not found at {layer2_config_path}, using defaults")
        cfg["layer2"] = {
            "config_path": None,
            "checkpoint_path": "/data1/chenyuxuan/Layer2/ckpt/0115/layer2_pretrain.pt",
            "gvp_root": "/data1/chenyuxuan/MSMLM",
            "gvp_ckpt_path": "/data1/chenyuxuan/checkpoint/gvp_weights_best.pt",
        }
    
    # ç¡®ä¿ train é…ç½®å­˜åœ¨å¹¶è®¾ç½® use_layer2
    if "train" not in cfg:
        cfg["train"] = {}
    cfg["train"]["use_layer2"] = True
    print(f"[INFO] Layer2 enabled in config (train.use_layer2=True)")
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®
    if not cfg.get("ckpt_dir"):
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ checkpoint_dir æˆ– llm_name_or_path")
    
    print(f"ğŸ“¦ ä½¿ç”¨ checkpoint: {cfg['ckpt_dir']}")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
    generator = MolAwareGenerator2()
    generator.load(cfg)
    
    # åŠ è½½æŸ¥è¯¢
    if args.input:
        print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æŸ¥è¯¢: {args.input}")
        queries = load_queries(args.input)
        print(f"   æ‰¾åˆ° {len(queries)} æ¡æŸ¥è¯¢")
    elif args.use_chembench or not args.input:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œé»˜è®¤ä½¿ç”¨ ChemBench
        print(f"ğŸ“‚ ä» ChemBench åŠ è½½æ•°æ®")
        queries = load_chembench_data(task=args.chembench_task, split=args.chembench_split)
        print(f"   æ‰¾åˆ° {len(queries)} æ¡æŸ¥è¯¢")
    else:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --input æˆ–ä½¿ç”¨ --use_chembench")
        return
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print("ğŸ”„ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    generate_training_data(
        generator=generator,
        queries=queries,
        output_path=args.output,
        task_type=args.task_type,
    )
    
    print("âœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
