#!/usr/bin/env python3
"""
Layer2 æ¨¡å‹éªŒè¯è„šæœ¬
ä½¿ç”¨ Layer2 æµ‹è¯•é›†éªŒè¯æ¨¡å‹è¾“å‡ºæ˜¯å¦æ­£å¸¸
"""

import sys
import json
import math
from pathlib import Path
from typing import List, Dict, Any
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from modules.layer2_component.Layer2Inferer import Layer2Inferer
from modules.layer2_component.gvp_embedder import build_gvp_encoder

def load_test_samples(test_file: str, max_samples: int = 10) -> List[Dict[str, Any]]:
    """åŠ è½½æµ‹è¯•æ ·æœ¬"""
    samples = []
    with open(test_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= max_samples:
                break
            if line.strip():
                samples.append(json.loads(line))
    return samples

def validate_layer2(
    layer2_inferer: Layer2Inferer,
    test_samples: List[Dict[str, Any]],
    device: str = "cuda:0"
):
    """éªŒè¯ Layer2 æ¨¡å‹"""
    print(f"\n{'='*80}")
    print(f"Layer2 æ¨¡å‹éªŒè¯")
    print(f"{'='*80}\n")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}\n")
    
    yield_bins = []
    yield_regs = []
    bin_logits_stats = []
    
    for i, sample in enumerate(test_samples):
        print(f"\næ ·æœ¬ {i+1}/{len(test_samples)}:")
        print(f"  ååº”: {sample.get('rxn', 'N/A')[:100]}...")
        
        # æå–ååº”ç‰© SMILESï¼ˆä» tokens ä¸­æå–ï¼‰
        tokens = sample.get("tokens", [])
        
        # ä» tokens ä¸­æå–ååº”ç‰©ä¿¡æ¯
        reactant_smiles_list = []
        reactant_embeddings = []
        amount_info_list = []
        
        for token in tokens:
            role = token.get("reaction_role", token.get("role", ""))
            if role == "REACTANT":
                # å°è¯•ä» token ä¸­è·å– SMILESï¼ˆå¦‚æœæœ‰ï¼‰
                smiles = token.get("smiles") or token.get("reactant_smiles")
                emb = token.get("emb")
                
                if emb is not None:
                    reactant_embeddings.append(torch.tensor(emb, device=device, dtype=torch.float32))
                    if smiles:
                        reactant_smiles_list.append(smiles)
                    else:
                        reactant_smiles_list.append("C")  # å ä½ç¬¦
                    
                    # æå– amount ä¿¡æ¯ï¼ˆä» log å€¼åæ¨ï¼Œä½†è¿™é‡Œæˆ‘ä»¬åªç”¨äºéªŒè¯ï¼Œå¯ä»¥ç®€åŒ–ï¼‰
                    amt_moles_log = token.get("amt_moles_log")
                    amt_mass_log = token.get("amt_mass_log")
                    amt_volume_log = token.get("amt_volume_log")
                    
                    # å¦‚æœæœ‰ log å€¼ï¼Œéœ€è¦å log1pï¼ˆä½†è¿™é‡Œæˆ‘ä»¬åªç”¨äºéªŒè¯ï¼Œå¯ä»¥ç®€åŒ–ï¼‰
                    # æ³¨æ„ï¼šamount_info åº”è¯¥ä½¿ç”¨åŸå§‹å€¼ï¼Œä¸æ˜¯ log å€¼
                    amount_info_list.append({
                        "moles": math.expm1(amt_moles_log) if amt_moles_log is not None else 1.0,
                        "mass": math.expm1(amt_mass_log) if amt_mass_log is not None else 0.0,
                        "volume": math.expm1(amt_volume_log) if amt_volume_log is not None else 0.0,
                    })
        
        if not reactant_embeddings:
            print("  âš ï¸  æœªæ‰¾åˆ°ååº”ç‰©ï¼Œè·³è¿‡")
            continue
        
        # ä½¿ç”¨ Layer2 é¢„æµ‹
        try:
            # å¦‚æœæœ‰å¤šä¸ªååº”ç‰©ï¼Œä½¿ç”¨åˆ—è¡¨ï¼›å¦åˆ™ä½¿ç”¨å•ä¸ª
            if len(reactant_embeddings) == 1:
                gvp_embedding = reactant_embeddings[0]
                reactant_smiles = reactant_smiles_list[0] if reactant_smiles_list else "C"
                amount_info = amount_info_list[0] if amount_info_list else None
            else:
                gvp_embedding = reactant_embeddings
                reactant_smiles = reactant_smiles_list if reactant_smiles_list else ["C"] * len(reactant_embeddings)
                amount_info = amount_info_list if amount_info_list else None
            
            result = layer2_inferer.predict(
                reactant_smiles=reactant_smiles,
                gvp_embedding=gvp_embedding,
                amount_info=amount_info,
            )
            
            yield_bin = result['yield_bin']
            yield_reg = result['yield_reg']
            yield_bins.append(yield_bin)
            yield_regs.append(yield_reg)
            
            print(f"  yield_bin: {yield_bin} (åŒºé—´: {yield_bin*10}%-{(yield_bin+1)*10}%)")
            print(f"  yield_reg: {yield_reg:.3f} ({yield_reg*100:.1f}%)")
            
            # å¦‚æœæœ‰ logits ä¿¡æ¯ï¼Œæ˜¾ç¤º
            if 'logits' in result:
                logits = result['logits']
                probs = result.get('probs', torch.softmax(torch.tensor(logits), dim=0).tolist())
                logits_std = result.get('logits_std', 0.0)
                logits_range = result.get('logits_range', 0.0)
                print(f"  bin_logits: {[f'{x:.2f}' for x in logits]}")
                print(f"  bin_probs: {[f'{x:.3f}' for x in probs]}")
                print(f"  logits_std: {logits_std:.4f}, logits_range: {logits_range:.4f}")
                if logits_std < 0.1 or logits_range < 0.5:
                    print(f"  âš ï¸  è­¦å‘Š: logits å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½æ¨¡å‹æœ‰é—®é¢˜")
            
            # å¦‚æœæœ‰çœŸå®å€¼ï¼Œæ¯”è¾ƒ
            if "yield_bin" in sample:
                true_bin = sample["yield_bin"]
                true_reg = sample.get("yield_reg", 0.0)
                bin_correct = "âœ…" if yield_bin == true_bin else "âŒ"
                reg_diff = abs(yield_reg - true_reg)
                print(f"  çœŸå®å€¼: bin={true_bin}, reg={true_reg:.3f}")
                print(f"  é¢„æµ‹: bin={yield_bin} {bin_correct}, reg={yield_reg:.3f} (è¯¯å·®: {reg_diff:.3f})")
        
        except Exception as e:
            print(f"  âŒ é¢„æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ç»Ÿè®¡ä¿¡æ¯
    if yield_bins:
        print(f"\n{'='*80}")
        print(f"ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'='*80}")
        print(f"yield_bin åˆ†å¸ƒ: {dict(zip(*torch.unique(torch.tensor(yield_bins), return_counts=True)))}")
        print(f"yield_bin èŒƒå›´: {min(yield_bins)} - {max(yield_bins)}")
        print(f"yield_reg èŒƒå›´: {min(yield_regs):.3f} - {max(yield_regs):.3f}")
        print(f"yield_reg å‡å€¼: {sum(yield_regs)/len(yield_regs):.3f}")
        print(f"yield_reg æ ‡å‡†å·®: {torch.std(torch.tensor(yield_regs)).item():.3f}")
        
        # æ£€æŸ¥ yield_bin æ˜¯å¦æ€»æ˜¯ç›¸åŒ
        if len(set(yield_bins)) == 1:
            print(f"\nâš ï¸  è­¦å‘Š: æ‰€æœ‰æ ·æœ¬çš„ yield_bin éƒ½ç›¸åŒ ({yield_bins[0]})ï¼Œå¯èƒ½æ¨¡å‹æœ‰é—®é¢˜")
        else:
            print(f"\nâœ… yield_bin æœ‰å˜åŒ–ï¼ŒèŒƒå›´: {min(yield_bins)} - {max(yield_bins)}")
        
        # æ£€æŸ¥ yield_reg çš„å˜åŒ–èŒƒå›´
        reg_range = max(yield_regs) - min(yield_regs)
        if reg_range < 0.1:
            print(f"\nâš ï¸  è­¦å‘Š: yield_reg å˜åŒ–èŒƒå›´å¾ˆå° ({reg_range:.3f})ï¼Œå¯èƒ½æ¨¡å‹è¾“å‡ºä¸å¤Ÿæ•æ„Ÿ")
        else:
            print(f"\nâœ… yield_reg æœ‰åˆç†å˜åŒ–ï¼ŒèŒƒå›´: {reg_range:.3f}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="éªŒè¯ Layer2 æ¨¡å‹")
    parser.add_argument("--test_file", type=str, 
                        default="/data1/chenyuxuan/Layer2/data/pretrain/dev.jsonl",
                        help="æµ‹è¯•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--config", type=str,
                        default=str(project_root / "modules" / "layer2_component" / "layer2_config.yaml"),
                        help="Layer2 é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¾å¤‡")
    parser.add_argument("--max_samples", type=int, default=20, help="æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°")
    
    args = parser.parse_args()
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_file = Path(args.test_file)
    if not test_file.exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        print(f"   è¯·æä¾›æœ‰æ•ˆçš„æµ‹è¯•æ–‡ä»¶è·¯å¾„")
        return
    
    print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
    test_samples = load_test_samples(str(test_file), args.max_samples)
    print(f"   åŠ è½½äº† {len(test_samples)} ä¸ªæ ·æœ¬\n")
    
    # åˆå§‹åŒ– Layer2
    print(f"ğŸ“¦ åˆå§‹åŒ– Layer2...")
    layer2_inferer = Layer2Inferer(
        config_path=args.config,
        device=args.device,
    )
    print(f"âœ… Layer2 åˆå§‹åŒ–å®Œæˆ\n")
    
    # éªŒè¯
    validate_layer2(layer2_inferer, test_samples, args.device)

if __name__ == "__main__":
    main()
